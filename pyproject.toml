[project]
name = "llena"
version = "0.1.0"
description = "gives vision to a small qwen2.5"
readme = "README.md"
requires-python = "==3.13.*"
dependencies = [
  "accelerate>=1.12.0",
  "bitsandbytes>=0.49.1",
  "datasets>=4.4.2",
  "python-dotenv>=1.1.1",
  "evaluate>=0.4.6",
  "gradio>=6.3.0",
  "numpy>=2.4.1",
  "peft>=0.18.1",
  "pillow>=12.1.0",
  "pyyaml>=5.3.1",
  "rich>=14.2.0",
  "safetensors>=0.7.0",
  "torch>=2.10.0",
  "torchvision>=0.2.0",
  "tqdm>=4.67.1",
  "transformers==5.1.0",
  "typer>=0.21.1",
  "wandb>=0.23.1",
]

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[tool.uv.sources]
torch = { index = "pytorch-cu128" }
torchvision = { index = "pytorch-cu128" }

[dependency-groups]
dev = ["ipython>=9.9.0", "pyright>=1.1.408", "pytest>=9.0.2"]
flash = ["flash-attn @ https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.7.16/flash_attn-2.8.3+cu128torch2.10-cp313-cp313-linux_x86_64.whl"]

[tool.ruff]
line-length = 120

[tool.ruff.lint.per-file-ignores]
"**/scripts/*.py" = ["E501"]

[tool.pyright]
reportConstantRedefinition = false
