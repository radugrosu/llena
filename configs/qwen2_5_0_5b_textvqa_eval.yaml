# configs/qwen2_5_0_5b_textvqa_eval.yaml
project:
  name: llena
  run_name: "qwen2.5-0.5b_siglip_mlp2_textvqa_eval"

paths:
  artifacts_dir: "artifacts"
  reports_dir: "reports"
  cache_dir: "${HF_HOME:-.cache/huggingface}"

model:
  llm_name: "Qwen/Qwen2.5-0.5B-Instruct"
  vision_name: "google/siglip-base-patch16-224"
  llm_revision: null
  vision_revision: null

mm:
  num_image_tokens: 256
  projector: "mlp2"
  perceiver_latents: 64
  perceiver_layers: 2

train:
  seed: 42
  device: "auto"
  precision: "bf16"
  gradient_checkpointing: false

  use_lora: true
  use_qlora: false
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  lora_targets: ["q_proj", "k_proj", "v_proj", "o_proj"]

  lr_lora: 1.0e-4
  lr_projector: 2.0e-4
  weight_decay: 0.0
  warmup_ratio: 0.03
  max_grad_norm: 1.0

  max_seq_len: 512
  batch_size: 2
  micro_batch_size: 2

  log_every: 10
  eval_every: 0
  save_every: 0
  save_total_limit: 1

data:
  dataset: "textvqa"
  data_dir: "datasets/processed"
  split: "validation"
  num_samples: 0
  image_size: 224

eval:
  enabled: true
  max_samples: 0
  batch_size: 2

logging:
  backend: "none"
  wandb_project: null
