project:
  name: llena
paths:
  artifacts_dir: artifacts
  reports_dir: reports
  cache_dir: ${HF_HOME:-.cache/huggingface}
model:
  llm_name: Qwen/Qwen2.5-0.5B-Instruct
  vision_name: google/siglip-base-patch16-224
  llm_revision: null
  vision_revision: null
mm:
  projector: mlp2
train:
  seed: 42
  device: cpu
  precision: bf16
  gradient_checkpointing: false
  use_lora: false
  use_qlora: false
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  lora_targets:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
  lr_lora: 0.0001
  lr_projector: 0.001
  weight_decay: 0.0
  warmup_ratio: 0.03
  lr_schedule: cosine
  max_grad_norm: 0.0
  max_seq_len: 128
  epochs: 1
  batch_size: 16
  micro_batch_size: 1
  log_every: 1
  eval_max_samples: 10
  eval_every: 5
  save_every: 5
  save_total_limit: 2
  max_steps: 5
data:
  dataset: sharegpt4v_coco
  data_dir: datasets/processed
  split: train
  num_samples: 500
logging:
  backend: wandb
  wandb_project: llena
